{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a05049c0-283e-490a-8f73-0d0c7a14c112",
   "metadata": {},
   "source": [
    "---\n",
    "## Chapter 5 â€“ First Steps with PyTorch\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031529f5-2bf0-487e-b8bb-fb9390f8f815",
   "metadata": {},
   "source": [
    "## Mini-Lab* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dfa0714-fff5-45eb-802e-a50ae19747b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.08370634 1.20326181 2.34567896]\n",
      "tensor([1.0837, 1.2033, 2.3457])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "np_rng = np.random.default_rng(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# NumPy baseline\n",
    "arr = np_rng.normal(size=(3, 2))\n",
    "norm_numpy = np.linalg.norm(arr, axis=1)\n",
    "\n",
    "# PyTorch equivalent\n",
    "ten = torch.tensor(arr, dtype=torch.float32)\n",
    "norm_torch = ten.norm(dim=1)\n",
    "\n",
    "print(norm_numpy)\n",
    "print(norm_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159455b9-00c8-4e5a-980e-52f4a226c44f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68887ac-630b-482b-b2cf-870131c64951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 00 | x=3.2000 | loss=2.250000\n",
      "step 01 | x=2.9600 | loss=1.440000\n",
      "step 02 | x=2.7680 | loss=0.921600\n",
      "step 03 | x=2.6144 | loss=0.589824\n",
      "step 04 | x=2.4915 | loss=0.377488\n",
      "step 05 | x=2.3932 | loss=0.241592\n",
      "step 06 | x=2.3146 | loss=0.154619\n",
      "step 07 | x=2.2517 | loss=0.098956\n",
      "step 08 | x=2.2013 | loss=0.063332\n",
      "step 09 | x=2.1611 | loss=0.040532\n",
      "step 10 | x=2.1288 | loss=0.025941\n",
      "step 11 | x=2.1031 | loss=0.016602\n",
      "step 12 | x=2.0825 | loss=0.010625\n",
      "step 13 | x=2.0660 | loss=0.006800\n",
      "step 14 | x=2.0528 | loss=0.004352\n",
      "step 15 | x=2.0422 | loss=0.002785\n",
      "step 16 | x=2.0338 | loss=0.001783\n",
      "step 17 | x=2.0270 | loss=0.001141\n",
      "step 18 | x=2.0216 | loss=0.000730\n",
      "step 19 | x=2.0173 | loss=0.000467\n",
      "step 20 | x=2.0138 | loss=0.000299\n",
      "step 21 | x=2.0111 | loss=0.000191\n",
      "step 22 | x=2.0089 | loss=0.000123\n",
      "step 23 | x=2.0071 | loss=0.000078\n",
      "step 24 | x=2.0057 | loss=0.000050\n",
      "step 25 | x=2.0045 | loss=0.000032\n",
      "step 26 | x=2.0036 | loss=0.000021\n",
      "step 27 | x=2.0029 | loss=0.000013\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([3.5], requires_grad=True)\n",
    "lr = 0.1\n",
    "\n",
    "for step in range(28):\n",
    "    loss = (x - 2.0) ** 2 # simple quadratic\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        x -= lr * x.grad\n",
    "    x.grad.zero_()\n",
    "    print(f\"step {step:02d} | x={x.item():.4f} | loss={loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803872b6-9e2f-4c2e-bfd3-0d5b2d20881b",
   "metadata": {},
   "source": [
    "## Exercises \n",
    "1. Write a small function using broadcasting only; verify shape math explicitly.\n",
    "2. Build a mini autograd example (scalar or vector) and sanity-check gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57786326-e313-454a-ab48-af9bbf8dd991",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "### Step 1 â€“ Use Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c981f-705a-4e24-9ff7-e41d8cebfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def pairwise_distances(A, B):\n",
    "    \"\"\"\n",
    "    Compute pairwise Euclidean distances between A and B using broadcasting only.\n",
    "    A: tensor of shape [m, d]\n",
    "    B: tensor of shape [n, d]\n",
    "    Returns: tensor of shape [m, n]\n",
    "    \"\"\"\n",
    "    # Reshape for broadcasting\n",
    "    A_exp = A[:, None, :]    # [m, 1, d]\n",
    "    B_exp = B[None, :, :]    # [1, n, d]\n",
    "    \n",
    "    # Subtract with broadcasting â†’ [m, n, d]\n",
    "    diff = A_exp - B_exp\n",
    "    \n",
    "    # Square, sum along the last dimension (d)\n",
    "    dist_sq = (diff ** 2).sum(dim=-1)\n",
    "    \n",
    "    # Take sqrt â†’ [m, n]\n",
    "    return torch.sqrt(dist_sq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235ff0c1-4a3b-408c-a04b-dec05c9acb1e",
   "metadata": {},
   "source": [
    "## Step 2 â€“ Verify Shape Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a71f761f-992f-4fd7-a90a-8673b6213204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape: torch.Size([2, 2])\n",
      "B shape: torch.Size([3, 2])\n",
      "D shape: torch.Size([2, 3])\n",
      "tensor([[5.6569, 8.4853, 2.0000],\n",
      "        [2.8284, 5.6569, 4.4721]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])   # shape [2, 2]\n",
    "B = torch.tensor([[5.0, 6.0], [7.0, 8.0], [1.0, 0.0]])  # shape [3, 2]\n",
    "\n",
    "print(\"A shape:\", A.shape)\n",
    "print(\"B shape:\", B.shape)\n",
    "\n",
    "D = pairwise_distances(A, B)\n",
    "print(\"D shape:\", D.shape)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ffee34-bade-401e-bd4f-1dc07e90f9ad",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "### Mini Autograd Example (Scalar + Vector Cases)\n",
    "### Scalar Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49979c3c-56ef-4795-8f35-8d0bc02f50df",
   "metadata": {},
   "source": [
    "$$\n",
    "y = w^2 + 3w + 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dw} = 2w + 3\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dw}\\Big|_{w=2} = 2(2) + 3 = 7\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c21a1670-c622-44e9-b7d5-88f68114ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: 2.0\n",
      "y: 11.0\n",
      "w.grad: 7.0\n"
     ]
    }
   ],
   "source": [
    "# Define a scalar tensor with gradient tracking\n",
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Define a simple differentiable function\n",
    "y = w**2 + 3*w + 1   # y = w^2 + 3w + 1\n",
    "\n",
    "# Compute gradient dy/dw\n",
    "y.backward()\n",
    "\n",
    "print(\"w:\", w.item())\n",
    "print(\"y:\", y.item())\n",
    "print(\"w.grad:\", w.grad.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaecd02-315a-47f1-b33a-3a0ced2386f3",
   "metadata": {},
   "source": [
    "### Vector Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b58de-f3e5-42d5-b894-742ad21a7b04",
   "metadata": {},
   "source": [
    "$$\n",
    "y = \\sum_i \\big( w_i^2 + 3w_i + 1 \\big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial w_i} = 2w_i + 3\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial w} =\n",
    "\\begin{bmatrix}\n",
    "2(1)+3 \\\\\n",
    "2(2)+3 \\\\\n",
    "2(3)+3\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "5 \\\\\n",
    "7 \\\\\n",
    "9\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c63444-2993-4e34-a8df-c7b6294ee8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: tensor([1., 2., 3.], requires_grad=True)\n",
      "y: 35.0\n",
      "w.grad: tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "# Reset\n",
    "w = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# Vectorized function: y = (w^2 + 3w + 1).sum()\n",
    "y = (w**2 + 3*w + 1).sum()\n",
    "\n",
    "# Backprop\n",
    "y.backward()\n",
    "\n",
    "print(\"w:\", w)\n",
    "print(\"y:\", y.item())\n",
    "print(\"w.grad:\", w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345655ca-307f-478e-84d8-aea33982ad6c",
   "metadata": {},
   "source": [
    "### Optional Gradient Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d791bf1f-076b-49ab-8299-b08a0fab946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradcheck passed: True\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import gradcheck\n",
    "\n",
    "w = torch.tensor([1.0, 2.0, 3.0], dtype=torch.double, requires_grad=True)\n",
    "\n",
    "def func(x):\n",
    "    return (x**2 + 3*x + 1).sum()\n",
    "\n",
    "test = gradcheck(func, (w,), eps=1e-6, atol=1e-4)\n",
    "print(\"Gradcheck passed:\", test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551219b-5be5-4e34-9cd4-c13c9093fd66",
   "metadata": {},
   "source": [
    "### Summary Formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1084743-bf9e-4702-956c-3e606f0f4162",
   "metadata": {},
   "source": [
    "$$\n",
    "y_{\\text{scalar}} = w^2 + 3w + 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dw} = 2w + 3\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_{\\text{vector}} = \\sum_i (w_i^2 + 3w_i + 1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla_w y = [\\, 2w_1 + 3,\\; 2w_2 + 3,\\; 2w_3 + 3 \\,]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c116fd31-31c7-4d0b-a123-e08db39a2a5e",
   "metadata": {},
   "source": [
    "### Exercise 1 â€” Environment Check\n",
    "Run the environment check and confirm versions and device information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c30c53-e7fe-4ca1-b64b-bd693b935a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version  : 3.12.11\n",
      "Torch version   : 2.8.0\n",
      "CUDA available  : False\n",
      "CUDA device     : CPU only\n"
     ]
    }
   ],
   "source": [
    "# Run PyTorch environment check\n",
    "import torch, platform\n",
    "\n",
    "print(f\"Python version  : {platform.python_version()}\")\n",
    "print(f\"Torch version   : {torch.__version__}\")\n",
    "print(f\"CUDA available  : {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device     : {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU only'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0184c017-57f0-4362-85de-633f75e787b3",
   "metadata": {},
   "source": [
    "### Exercise 2 â€” NumPy â†” PyTorch Equivalence\n",
    "- Tensor creation \n",
    "- Broadcasting  \n",
    "- Reduction\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Broadcasting: } (3\\times1) + (1\\times2) \\Rightarrow (3\\times2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Reduction: } \\text{mean}(a_{ij}) = \\frac{1}{n} \\sum_{i,j} a_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e37690-b5bd-4eb4-8717-7c520765e9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor equality: True\n",
      "Broadcast check: True\n",
      "Numpy mean: 2.5 Torch mean: 2.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Tensor creation\n",
    "a_np = np.array([[1, 2], [3, 4]])\n",
    "a_torch = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"Tensor equality:\", np.allclose(a_np, a_torch.numpy()))\n",
    "\n",
    "# Broadcasting\n",
    "b_np = np.array([[1], [2], [3]])\n",
    "c_np = np.array([10, 20])\n",
    "res_np = b_np + c_np\n",
    "\n",
    "b_torch = torch.tensor([[1], [2], [3]])\n",
    "c_torch = torch.tensor([10, 20])\n",
    "res_torch = b_torch + c_torch\n",
    "\n",
    "print(\"Broadcast check:\", np.allclose(res_np, res_torch.numpy()))\n",
    "\n",
    "# Reduction\n",
    "print(\"Numpy mean:\", a_np.mean(), \"Torch mean:\", a_torch.float().mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08c8e76-bc00-45c5-b67e-f7936305aa6a",
   "metadata": {},
   "source": [
    "### Exercise 3 â€” Autograd Demo\n",
    "Create tensor `x` with `requires_grad=True`, compute a quadratic loss, backpropagate, and inspect gradients.\n",
    "\n",
    "#### Function\n",
    "\n",
    "$$\n",
    "y = (x - 3)^2 + 2x\n",
    "$$\n",
    "\n",
    "\n",
    "#### Derivative\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = 2(x - 3) + 2\n",
    "$$\n",
    "\n",
    "\n",
    "$ At ð‘¥ = 5 x=5 $\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx}\\Big|_{x=5} = 2(5 - 3) + 2 = 6\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "427a00d1-d7bb-42b3-b3c6-20d09a86d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 5.0\n",
      "y: 14.0\n",
      "dy/dx: 6.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "y = (x - 3)**2 + 2*x  # sample quadratic loss\n",
    "\n",
    "y.backward()\n",
    "print(\"x:\", x.item())\n",
    "print(\"y:\", y.item())\n",
    "print(\"dy/dx:\", x.grad.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127556bf-2e36-4395-8061-9d419943dbed",
   "metadata": {},
   "source": [
    "### Exercise 4 â€” Manual Gradient Descent\n",
    "Perform a few steps of gradient descent on \\( y=(x-3)^2 \\) and track progress.\n",
    "\n",
    "#### Function\n",
    "$$\n",
    "y = (x - 3)^2\n",
    "$$\n",
    "\n",
    "\n",
    "#### Gradient\n",
    "$$\n",
    "\\frac{dy}{dx} = 2(x - 3)\n",
    "$$\n",
    "\n",
    "#### Gradient Descent Update Rule\n",
    "$$\n",
    "x_{t+1} = x_t - \\eta \\, \\frac{dy}{dx}\n",
    "$$\n",
    "\n",
    "\n",
    "#### At Convergence\n",
    "$$\n",
    "x^* = 3,\\quad y^* = 0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b761ddb-5644-451a-920e-be7fb61f0c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: x=0.0000, y=9.0000, grad=-6.0000\n",
      "Step 1: x=0.6000, y=5.7600, grad=-4.8000\n",
      "Step 2: x=1.0800, y=3.6864, grad=-3.8400\n",
      "Step 3: x=1.4640, y=2.3593, grad=-3.0720\n",
      "Step 4: x=1.7712, y=1.5099, grad=-2.4576\n",
      "Step 5: x=2.0170, y=0.9664, grad=-1.9661\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "lr = 0.1\n",
    "for step in range(6):\n",
    "    y = (x - 3)**2\n",
    "    y.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(f\"Step {step}: x={x.item():.4f}, y={y.item():.4f}, grad={x.grad.item():.4f}\")\n",
    "        x -= lr * x.grad\n",
    "        x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ad2c9-7b0a-4f11-aae5-4ec9d848b051",
   "metadata": {},
   "source": [
    "### Exercise 5 â€” torch.no_grad() Demonstration\n",
    "Update a parameter within `torch.no_grad()` and verify gradients stay frozen.\n",
    "\n",
    "#### Function\n",
    "$$\n",
    "y = (w - 5)^2\n",
    "$$\n",
    "\n",
    "\n",
    "#### Gradient\n",
    "$$\n",
    "\\frac{dy}{dw} = 2(w - 5)\n",
    "$$\n",
    "\n",
    "\n",
    "#### Update Step\n",
    "$$\n",
    "w_{\\text{new}} = w_{\\text{old}} - \\eta \\, \\frac{dy}{dw}\n",
    "$$\n",
    "\n",
    "#### When inside `torch.no_grad()`\n",
    "$$\n",
    "\\nabla_w \\text{ (update) } = 0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07c69156-3cdb-4ffc-b17b-897963b48304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before update â†’ w.grad: -6.0\n",
      "After update â†’ w: 3.8000001907348633\n",
      "Grad after update (should be 0): 0.0\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Forward + backward\n",
    "loss = (w - 5)**2\n",
    "loss.backward()\n",
    "print(\"Before update â†’ w.grad:\", w.grad.item())\n",
    "\n",
    "# Parameter update without tracking\n",
    "with torch.no_grad():\n",
    "    w -= 0.3 * w.grad\n",
    "    w.grad.zero_()\n",
    "\n",
    "print(\"After update â†’ w:\", w.item())\n",
    "print(\"Grad after update (should be 0):\", w.grad.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2530168-a052-4c23-b02b-51dfae7fd994",
   "metadata": {},
   "source": [
    "## Challenges Chapter 5\n",
    "### Challenge 1 â€” Linear Regression: NumPy â†’ PyTorch\n",
    "Weâ€™ll port a NumPy-based linear regression to pure PyTorch tensors and compare results to `scikit-learn`â€™s LinearRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9102c44-13c6-4cf2-a6c5-0c1fc5de104f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = X w + b\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{N} \\sum_i (\\hat{y}_i - y_i)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla_w \\mathcal{L} = \\frac{2}{N} X^\\top (Xw + b - y)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be812b91-85ab-42d9-b919-19f20f381f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch results â†’ w=2.9029, b=2.0682, loss=0.010637\n",
      "Sklearn results  â†’ w=2.9937, b=2.0222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X_np = np.random.rand(100, 1)\n",
    "y_np = 3 * X_np.squeeze() + 2 + np.random.randn(100) * 0.1\n",
    "\n",
    "# Convert to torch tensors\n",
    "X = torch.tensor(X_np, dtype=torch.float32)\n",
    "y = torch.tensor(y_np, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Initialize parameters\n",
    "w = torch.randn(1, 1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# Train with gradient descent\n",
    "lr = 0.1\n",
    "for _ in range(200):\n",
    "    y_pred = X @ w + b\n",
    "    loss = ((y_pred - y)**2).mean()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "        b -= lr * b.grad\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "print(f\"PyTorch results â†’ w={w.item():.4f}, b={b.item():.4f}, loss={loss.item():.6f}\")\n",
    "\n",
    "# Compare to scikit-learn\n",
    "lr_sklearn = LinearRegression().fit(X_np, y_np)\n",
    "print(f\"Sklearn results  â†’ w={lr_sklearn.coef_[0]:.4f}, b={lr_sklearn.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910ac7a-b537-45b4-af1c-7e627b1ba17f",
   "metadata": {},
   "source": [
    "### Challenge 2 â€” CPU vs GPU Benchmark\n",
    "Compare CPU and GPU matrix multiply speed, including data transfer overheads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7cba5-e458-479b-b316-e66ef80649d7",
   "metadata": {},
   "source": [
    "$$\n",
    "C = A \\times B\n",
    "$$\n",
    "\n",
    "$$\n",
    "t_{\\text{total}} = t_{\\text{transfer}}^{(h \\to d)} + t_{\\text{compute}}^{(gpu)} + t_{\\text{transfer}}^{(d \\to h)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed08219b-6eef-4469-8dac-1934ff44c97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ No CUDA device available\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "sizes = [100, 500, 1000, 5000, 10000]\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    for n in sizes:\n",
    "        A_cpu = torch.randn(n, n)\n",
    "        B_cpu = torch.randn(n, n)\n",
    "\n",
    "        # CPU benchmark\n",
    "        start = time.time()\n",
    "        _ = A_cpu @ B_cpu\n",
    "        cpu_time = time.time() - start\n",
    "\n",
    "        # GPU benchmark (including transfers)\n",
    "        start = time.time()\n",
    "        A_gpu, B_gpu = A_cpu.to(device), B_cpu.to(device)\n",
    "        torch.cuda.synchronize()\n",
    "        _ = A_gpu @ B_gpu\n",
    "        torch.cuda.synchronize()\n",
    "        gpu_time = time.time() - start\n",
    "\n",
    "        print(f\"{n:>5}Ã—{n:>5} | CPU: {cpu_time:.4f}s | GPU: {gpu_time:.4f}s\")\n",
    "else:\n",
    "    print(\"âš ï¸ No CUDA device available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33fa60b8-0e40-4230-9389-15793a4ec91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "  100Ã—  100 | Time: 0.0054s\n",
      "  500Ã—  500 | Time: 0.0029s\n",
      " 1000Ã— 1000 | Time: 0.0046s\n",
      " 2000Ã— 2000 | Time: 0.0219s\n",
      " 5000Ã— 5000 | Time: 0.1762s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "sizes = [100, 500, 1000, 2000, 5000]\n",
    "for n in sizes:\n",
    "    A = torch.randn(n, n, device=device)\n",
    "    B = torch.randn(n, n, device=device)\n",
    "    torch.mps.synchronize() if device.type == \"mps\" else None\n",
    "    start = time.time()\n",
    "    _ = A @ B\n",
    "    torch.mps.synchronize() if device.type == \"mps\" else None\n",
    "    print(f\"{n:>5}Ã—{n:>5} | Time: {time.time()-start:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06650e17-a1c2-4fb3-90ac-df42a0fa81ad",
   "metadata": {},
   "source": [
    "### Challenge 3 â€” Two-Layer MLP (Manual Tensor Ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233bef1-17da-40aa-b2e1-db9d650ddee2",
   "metadata": {},
   "source": [
    "$$\n",
    "z_1 = X W_1 + b_1\n",
    "$$\n",
    "\n",
    "$$\n",
    "a_1 = \\text{ReLU}(z_1) = \\max(0, z_1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y} = a_1 W_2 + b_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{N}\\sum_i (\\hat{y}_i - y_i)^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c00d2f1-d4f6-48cf-ab37-d07fef1b10d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 14.349802017211914\n",
      "Grad W1: torch.Size([3, 4])\n",
      "Grad W2: torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Synthetic data\n",
    "X = torch.randn(5, 3)\n",
    "y = torch.randn(5, 1)\n",
    "\n",
    "# Parameters\n",
    "W1 = torch.randn(3, 4, requires_grad=True)\n",
    "b1 = torch.randn(4, requires_grad=True)\n",
    "W2 = torch.randn(4, 1, requires_grad=True)\n",
    "b2 = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# Forward pass (manual ops)\n",
    "z1 = X @ W1 + b1\n",
    "a1 = torch.relu(z1)\n",
    "y_pred = a1 @ W2 + b2\n",
    "loss = ((y_pred - y)**2).mean()\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "print(\"Loss:\", loss.item())\n",
    "print(\"Grad W1:\", W1.grad.shape)\n",
    "print(\"Grad W2:\", W2.grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b175a-f518-4928-bdad-f7b61d03a93c",
   "metadata": {},
   "source": [
    "## Challenge 4 â€” Reproducibility (Set All Seeds)\n",
    "$$\n",
    "\\text{Seed all RNGs â†’ Python, NumPy, PyTorch (CPU/GPU)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Reproducibility: } f(\\text{seeded inputs}) = \\text{constant output across runs}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01edebcf-8939-42af-a594-17e22cfd265d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identical tensors: True\n",
      "x1: tensor([-0.1115,  0.1204, -0.3696])\n",
      "x2: tensor([-0.1115,  0.1204, -0.3696])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def set_all_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Demonstrate reproducibility\n",
    "set_all_seeds(123)\n",
    "x1 = torch.randn(3)\n",
    "set_all_seeds(123)\n",
    "x2 = torch.randn(3)\n",
    "\n",
    "print(\"Identical tensors:\", torch.allclose(x1, x2))\n",
    "print(\"x1:\", x1)\n",
    "print(\"x2:\", x2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
