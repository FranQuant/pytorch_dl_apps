{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2051b719-02c4-416a-b1bb-dc145c08d3bc",
   "metadata": {},
   "source": [
    "# *Deep Learning Basics with PyTorch*\n",
    "# Part I — Foundations of Machine Learning\n",
    "## Chapter 2: Data, Features, and Representations\n",
    "In this chapter, we reconstructed the classic \"Iris\" ML workflow using financial data.\n",
    "Each step — feature creation, visualization, model fitting, and boundary inspection —\n",
    "builds intuition for how machine learning interprets patterns in markets.\n",
    "\n",
    "The same pipeline underpins deep learning models, which we will explore in the next chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23202bc2-1b90-489c-8156-9bb71c2933dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8')  # plotting\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5bc98-1272-4fb7-9cc5-ab9431db8960",
   "metadata": {},
   "source": [
    "## Building a Machine Learning Dataset from ADR Market Data\n",
    "We start by transforming raw price and volume series for a chosen ADR (e.g. GGAL) into daily returns and volume changes — the simplest features capturing market direction and liquidity shifts.\n",
    "A binary target encodes whether the day closed up (1) or down (0).\n",
    "This preprocessing step mirrors classic feature extraction in ML, but applied to real market micro-structure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5711be-40d1-43f6-9908-1db92868413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load and prepare ADR data\n",
    "df = pd.read_csv(\"adr_prices_and_vol.csv\", parse_dates=[\"Date\"])\n",
    "ticker = \"GGAL\"\n",
    "\n",
    "# Select columns and drop missing values\n",
    "df_t = df[[\"Date\", f\"{ticker}_Price\", f\"{ticker}_Volume\"]].dropna().copy()\n",
    "\n",
    "# Create simple features (returns and volume change)\n",
    "df_t[\"Return_1d\"] = df_t[f\"{ticker}_Price\"].pct_change()\n",
    "df_t[\"VolChange\"] = df_t[f\"{ticker}_Volume\"].pct_change()\n",
    "df_t.dropna(inplace=True)\n",
    "\n",
    "# Create a simple binary target: 1 = Up day, 0 = Down day\n",
    "df_t[\"Target\"] = (df_t[\"Return_1d\"] > 0).astype(int)\n",
    "\n",
    "# --- Define global feature matrix and target vector ---\n",
    "features = [\"Return_1d\", \"VolChange\"]\n",
    "X = df_t[features].values\n",
    "y = df_t[\"Target\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9fb08-e8e0-48cf-b4d1-f26c22f1007c",
   "metadata": {},
   "source": [
    "## Load and Visualize Financial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee7d4a-2208-455c-a6ba-69cb3caa750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization (analogous to the Iris scatter)\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(\n",
    "    df_t.loc[df_t[\"Target\"] == 0, \"Return_1d\"],\n",
    "    df_t.loc[df_t[\"Target\"] == 0, \"VolChange\"],\n",
    "    label=\"Down Day\", marker=\"o\", alpha=0.6\n",
    ")\n",
    "plt.scatter(\n",
    "    df_t.loc[df_t[\"Target\"] == 1, \"Return_1d\"],\n",
    "    df_t.loc[df_t[\"Target\"] == 1, \"VolChange\"],\n",
    "    label=\"Up Day\", marker=\"^\", alpha=0.6\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Daily Return\")\n",
    "plt.ylabel(\"Volume Change\")\n",
    "plt.legend(frameon=False)\n",
    "plt.title(f\"{ticker} — Feature Space: Return vs Volume\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e3fec-082e-4d8b-9ce0-e0a76de77747",
   "metadata": {},
   "source": [
    "- This scatterplot shows how price momentum (returns) and trading activity (volume change) interact.\n",
    "- Up-days cluster differently from down-days, suggesting a weak but learnable pattern.\n",
    "- Visualization remains the most intuitive way to check separability before modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d8cf0b-a339-448f-8b72-2529e2291853",
   "metadata": {},
   "source": [
    "## Exploring Alternative Feature Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21061320-0af1-4891-a54e-1a506183ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature construction (5-day return and volatility)\n",
    "df_t = df[[\"Date\", f\"{ticker}_Price\"]].dropna().copy()\n",
    "df_t[\"Return_5d\"] = df_t[f\"{ticker}_Price\"].pct_change(5)\n",
    "df_t[\"Volatility_5d\"] = df_t[\"Return_5d\"].rolling(5).std()\n",
    "df_t.dropna(inplace=True)\n",
    "\n",
    "# --- Target: 1 = Up 5d return, 0 = Down 5d return\n",
    "df_t[\"Target\"] = (df_t[\"Return_5d\"] > 0).astype(int)\n",
    "\n",
    "# --- Visualization\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(\n",
    "    df_t.loc[df_t[\"Target\"] == 0, \"Return_5d\"],\n",
    "    df_t.loc[df_t[\"Target\"] == 0, \"Volatility_5d\"],\n",
    "    label=\"5-Day Down Period\", marker=\"o\", alpha=0.6\n",
    ")\n",
    "plt.scatter(\n",
    "    df_t.loc[df_t[\"Target\"] == 1, \"Return_5d\"],\n",
    "    df_t.loc[df_t[\"Target\"] == 1, \"Volatility_5d\"],\n",
    "    label=\"5-Day Up Period\", marker=\"^\", alpha=0.6\n",
    ")\n",
    "\n",
    "plt.xlabel(\"5-Day Return\")\n",
    "plt.ylabel(\"5-Day Rolling Volatility\")\n",
    "plt.legend(frameon=False)\n",
    "plt.title(f\"{ticker} — Alternative Feature Projection\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8324d1bf-10e7-40c2-9c6d-5f8b10867eae",
   "metadata": {},
   "source": [
    "- Feature engineering changes what patterns become visible.\n",
    "- Aggregating over five days smooths noise and introduces volatility as a second-order feature.\n",
    "- Here we see whether multi-day behavior offers better separability — a precursor to using richer\n",
    "temporal features or deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d6944f-35ff-408d-9e9d-efc41bd7c685",
   "metadata": {},
   "source": [
    "## Train a Scaler + Logistic Regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4bee5-7c7f-4f45-a7b1-01fda3fb5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train/Test split, scaling, and logistic regression ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, display_labels=[\"Down\", \"Up\"], cmap=\"Blues\"\n",
    ")\n",
    "plt.title(f\"{ticker} — Logistic Regression (Up vs Down Days)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da03989-20c7-4675-8f6c-ecde32d71f37",
   "metadata": {},
   "source": [
    "We apply a minimal ML pipeline — standardizing inputs ensures the model isn’t biased by scale differences between returns and volume changes. A logistic regression then estimates the probability of an up-day. Accuracy and the confusion matrix quantify how often the model gets direction right; interpret both rather than celebrating a single metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a46acb-4e80-4c5f-99b9-a6d3b48b8fe5",
   "metadata": {},
   "source": [
    "## Decision Boundary in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1ec22-328e-4dea-ad74-640728e4fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fit model on entire dataset for visualization ---\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
    "pipe.fit(X, y)\n",
    "\n",
    "# --- Create meshgrid across feature space ---\n",
    "xmin, xmax = X[:, 0].min() - 0.02, X[:, 0].max() + 0.02\n",
    "ymin, ymax = X[:, 1].min() - 0.02, X[:, 1].max() + 0.02\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(xmin, xmax, 300),\n",
    "    np.linspace(ymin, ymax, 300)\n",
    ")\n",
    "\n",
    "# --- Predict class across grid ---\n",
    "zz = pipe.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "# --- Plot boundary and data ---\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.contourf(xx, yy, zz, levels=[-0.5, 0.5, 1.5], cmap='coolwarm', alpha=0.2)\n",
    "\n",
    "plt.scatter(\n",
    "    X[y == 0, 0], X[y == 0, 1],\n",
    "    marker='o', label='Down Day', alpha=0.6\n",
    ")\n",
    "plt.scatter(\n",
    "    X[y == 1, 0], X[y == 1, 1],\n",
    "    marker='^', label='Up Day', alpha=0.6\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Daily Return\")\n",
    "plt.ylabel(\"Volume Change\")\n",
    "plt.legend(frameon=False)\n",
    "plt.title(f\"{ticker} — Logistic Regression Decision Boundary\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23532d6-cfce-4b58-9040-f2575bb2c661",
   "metadata": {},
   "source": [
    "- The decision boundary divides the 2-D feature space into regions the classifier labels as “Up” or “Down.”\n",
    "- In finance, such a boundary can be interpreted as a linear trading signal frontier — a simple function of return and liquidity change.\n",
    "- Inspect whether up-days sit mostly inside the predicted region; deviations hint at noise or regime shifts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
