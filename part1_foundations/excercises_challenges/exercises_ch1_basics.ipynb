{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da26bb83-7a1e-43c2-9ebf-f5147c5ee490",
   "metadata": {},
   "source": [
    "# Deep Learning Basics with PyTorch\n",
    "# Part I — Foundations of Machine Learning\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed656d3-d587-4b42-ace2-71f8677e9597",
   "metadata": {},
   "source": [
    "---\n",
    "## *Appendix A — NumPy Warm-Up*\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660a174a-e719-45b7-a38a-30ea145243b2",
   "metadata": {},
   "source": [
    "### Array Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96252b23-0d7a-4ef7-817f-3f82df4c93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "A = np.tile(np.arange(3).reshape(3,1), (1,4))\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a72740-8ee9-451b-b931-3fe66e784540",
   "metadata": {},
   "source": [
    "### Sampling and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba97c7-9fa3-49a6-82f8-12a42d0abc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"adr_prices_and_vol.csv\", parse_dates=[\"Date\"])\n",
    "ticker = \"CIB\"\n",
    "returns = df[f\"{ticker}_Price\"].pct_change().dropna()\n",
    "\n",
    "sample = returns.sample(10000, replace=True, random_state=42)\n",
    "print(f\"mean = {sample.mean():.6f}, std = {sample.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1504fdc-9312-4b79-946e-33f7e2788e28",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1459a2-6145-40ef-9400-97d6b1b01810",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 20\n",
    "X = np.lib.stride_tricks.sliding_window_view(returns, window_shape=window)\n",
    "X_centered = X - X.mean(axis=1, keepdims=True)\n",
    "\n",
    "print(\"Original window shape:\", X.shape)\n",
    "print(\"Centered matrix shape:\", X_centered.shape)\n",
    "print(X_centered[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c0970f-62f2-4591-958c-c98a6b551576",
   "metadata": {},
   "source": [
    "### Z-Score Standardization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8da2d-675d-4f29-a04d-c0c4b52be3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(X):\n",
    "    mu = X.mean(axis=0)\n",
    "    sigma = X.std(axis=0)\n",
    "    return (X - mu) / sigma\n",
    "\n",
    "features = df[[f\"{ticker}_Price\", f\"{ticker}_Volume\"]].pct_change().dropna().values\n",
    "features_z = zscore(features)\n",
    "features_z[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440128d8-83fc-47f5-a5bc-bbe0fa33bdf5",
   "metadata": {},
   "source": [
    "### Vectorized Squared Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95769050-49a4-4c21-9b3e-6011c775d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = features_z[0]\n",
    "b = features_z[1]\n",
    "sq_dist = np.sum((a - b)**2)\n",
    "sq_dist_vec = np.dot((a - b), (a - b))\n",
    "print(f\"Squared distance (loop-free): {sq_dist_vec:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31892b48-7cf2-465d-b0bb-ed8684d66730",
   "metadata": {},
   "source": [
    "---\n",
    "## *Chapter 1 – Introduction to ML*\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd63b4-8d89-4ad1-92ec-1fffa0fa95a0",
   "metadata": {},
   "source": [
    "## Implement MAE & MSE in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04573fd8-ccfb-4e81-8f5b-66caa7da91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Error\"\"\"\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    \"\"\"Mean Squared Error\"\"\"\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "y_true = returns.shift(-1).dropna().values\n",
    "y_pred = returns.iloc[:-1].values  \n",
    "\n",
    "print(f\"MAE: {mae(y_true, y_pred):.6f}\")\n",
    "print(f\"MSE: {mse(y_true, y_pred):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb3f880-80af-4132-8abf-9110caa7ce8e",
   "metadata": {},
   "source": [
    "### Fit Linear Regression on ADR Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6645c765-1353-40f2-a03a-36df77da5d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = returns.shift(1).dropna().values.reshape(-1, 1)\n",
    "y = returns.iloc[1:].values\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = linreg.predict(X_train)\n",
    "y_pred_test  = linreg.predict(X_test)\n",
    "\n",
    "print(f\"Coefficient: {linreg.coef_[0]:.6f}, Intercept: {linreg.intercept_:.6f}\")\n",
    "print(f\"Train R²: {linreg.score(X_train, y_train):.4f}\")\n",
    "print(f\"Test R² : {linreg.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d71e68d-4417-43e3-a2e9-572e43a791bb",
   "metadata": {},
   "source": [
    "## Chronological Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3595a1-8b3a-475e-bf9f-19bcdbdabf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_split(X, y, train_size=0.6, val_size=0.2):\n",
    "    \"\"\"Chronological split for time-series data.\"\"\"\n",
    "    n = len(X)\n",
    "    n_train = int(n * train_size)\n",
    "    n_val   = int(n * val_size)\n",
    "    X_train, y_train = X[:n_train], y[:n_train]\n",
    "    X_val,   y_val   = X[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
    "    X_test,  y_test  = X[n_train+n_val:],        y[n_train+n_val:]\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = time_split(X, y)\n",
    "print(len(X_train), len(X_val), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27928d30-ff19-4276-8436-049740cf8fa6",
   "metadata": {},
   "source": [
    "### Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b1058-1b7c-4747-8565-d06d1a2994ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "y_pred_test = linreg.predict(X_test)\n",
    "residuals = y_test - y_pred_test\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3.5))\n",
    "ax[0].scatter(y_pred_test, residuals, s=12, alpha=0.6)\n",
    "ax[0].axhline(0, color=\"k\", lw=1)\n",
    "ax[0].set_xlabel(\"Predicted Return\")\n",
    "ax[0].set_ylabel(\"Residual (y_true - y_pred)\")\n",
    "ax[0].set_title(\"Residuals vs Predictions\")\n",
    "\n",
    "ax[1].hist(residuals, bins=40, alpha=0.7)\n",
    "ax[1].set_title(\"Residual Distribution\")\n",
    "ax[1].set_xlabel(\"Residual\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107b25a5-77cc-44b6-ba6b-eed908ac53e6",
   "metadata": {},
   "source": [
    "### Challenge: Manual Gradient Descent for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b42da8-f4fd-4267-b998-3e2310e0024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_gd(X, y, lr=0.01, epochs=500):\n",
    "    \"\"\"Manual gradient descent for simple linear regression.\"\"\"\n",
    "    X = np.c_[np.ones(len(X)), X] \n",
    "    w = np.zeros(X.shape[1])\n",
    "    for _ in range(epochs):\n",
    "        grad = -2/len(X) * X.T @ (y - X @ w)\n",
    "        w -= lr * grad\n",
    "    return w\n",
    "\n",
    "w = linear_gd(X_train, y_train)\n",
    "print(f\"Intercept = {w[0]:.6f}, Slope = {w[1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb55c0-7147-4f05-8022-ad9839d0d0bd",
   "metadata": {},
   "source": [
    "### Challenge: logistic regression + decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a7aef7-52f8-4b08-b6c3-410062e12308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Challenge: Logistic Regression + Decision Boundary (Compact Version) ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "X = pd.DataFrame({\n",
    "    \"lag1\": returns.shift(1),\n",
    "    \"vol5\": returns.rolling(5).std()\n",
    "}).dropna()\n",
    "y = (returns[-len(X):] > 0).astype(int).values\n",
    "\n",
    "# --- Chronological Split (60/20/20) ---\n",
    "n = len(X)\n",
    "n_train, n_val = int(0.6 * n), int(0.2 * n)\n",
    "X_train, X_val, X_test = X[:n_train], X[n_train:n_train+n_val], X[n_train+n_val:]\n",
    "y_train, y_val, y_test = y[:n_train], y[n_train:n_train+n_val], y[n_train+n_val:]\n",
    "\n",
    "# --- Standardize & Fit ---\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "clf = LogisticRegression().fit(scaler.transform(X_train), y_train)\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = clf.predict(scaler.transform(X_test))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# --- Decision Boundary (Fixed for Feature Names Consistency) ---\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(X_test[\"lag1\"].min(), X_test[\"lag1\"].max(), 200),\n",
    "    np.linspace(X_test[\"vol5\"].min(), X_test[\"vol5\"].max(), 200)\n",
    ")\n",
    "\n",
    "# ✅ Create DataFrame with same column names as X_train\n",
    "grid = pd.DataFrame(np.c_[xx.ravel(), yy.ravel()], columns=X_train.columns)\n",
    "\n",
    "# Predict on the grid using the trained model and scaler\n",
    "Z = clf.predict(scaler.transform(grid)).reshape(xx.shape)\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=\"coolwarm\")\n",
    "plt.scatter(\n",
    "    X_test[\"lag1\"], X_test[\"vol5\"],\n",
    "    c=y_test, cmap=\"coolwarm\", s=20, edgecolor=\"k\"\n",
    ")\n",
    "plt.title(f\"Decision Boundary — Logistic Regression ({ticker} ADR)\")\n",
    "plt.xlabel(\"Lagged Return (z-scored)\")\n",
    "plt.ylabel(\"5-Day Volatility (z-scored)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1539538d-8a76-4537-9fc7-78b3f3ce80e0",
   "metadata": {},
   "source": [
    "### Challenge: logistic regression + unified evaluation function\n",
    "This helper evaluates regression or classification models using MAE/MSE or Accuracy/F1, depending on the `task` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf07af-bab8-413f-8ab1-78d7d34deb45",
   "metadata": {},
   "source": [
    "```python\n",
    "# Utility: Unified Model Evaluation Function\n",
    "# Helper function to evaluate regression or classification models quickly.\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, f1_score\n",
    "\n",
    "def evaluate_model(y_true, y_pred, task=\"regression\"):\n",
    "    \"\"\"Unified evaluation for regression or classification tasks.\"\"\"\n",
    "    if task == \"regression\":\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        print(f\"MAE: {mae:.4f} | MSE: {mse:.4f}\")\n",
    "    elif task == \"classification\":\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        f1  = f1_score(y_true, y_pred)\n",
    "        print(f\"Accuracy: {acc:.3f} | F1-score: {f1:.3f}\")\n",
    "```        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ea648-d089-4aaa-a953-1f94d5082874",
   "metadata": {},
   "source": [
    "#### Utility — Unified Evaluation Function (Return-Based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12525b3a-e2d3-4d55-9900-7c0a16efc768",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error,\n",
    "    accuracy_score, f1_score, precision_score, recall_score\n",
    ")\n",
    "\n",
    "def evaluate_model(y_true, y_pred, task=\"regression\"):\n",
    "    \"\"\"\n",
    "    Unified evaluation for regression or classification tasks.\n",
    "    Returns metrics as a dictionary for easy logging or DataFrame aggregation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        True target values.\n",
    "    y_pred : array-like\n",
    "        Predicted target values.\n",
    "    task : str, default='regression'\n",
    "        Type of task. One of {'regression', 'classification'}.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with evaluation metrics.\n",
    "    \"\"\"\n",
    "    if task == \"regression\":\n",
    "        return {\n",
    "            \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "            \"MSE\": mean_squared_error(y_true, y_pred)\n",
    "        }\n",
    "    elif task == \"classification\":\n",
    "        return {\n",
    "            \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "            \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "            \"F1\": f1_score(y_true, y_pred, zero_division=0)\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Task must be either 'regression' or 'classification'.\")\n",
    "```       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9ef74b-fa81-4666-bec2-4f43fc787463",
   "metadata": {},
   "source": [
    "---\n",
    "## Chapter 2 – Features and Representations (Standardization & Pipelines)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9024845d-0630-4f56-9eb4-f9a3c4f1cb99",
   "metadata": {},
   "source": [
    "### 1. Setup and Feature Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5535c438-7e79-4f44-8880-03ffe26dbbb8",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv(\"adr_prices_and_vol.csv\", parse_dates=[\"Date\"])\n",
    "ticker = \"NU\"\n",
    "\n",
    "df[\"Return_1d\"] = df[f\"{ticker}_Price\"].pct_change()\n",
    "df[\"Vol_5d\"] = df[f\"{ticker}_Price\"].pct_change().rolling(5).std()\n",
    "df[\"MA_10\"] = df[f\"{ticker}_Price\"].rolling(10).mean()\n",
    "df[\"MA_50\"] = df[f\"{ticker}_Price\"].rolling(50).mean()\n",
    "df[\"MA_ratio\"] = df[\"MA_10\"] / df[\"MA_50\"] - 1\n",
    "\n",
    "df[\"Target\"] = (df[\"Return_1d\"].shift(-1) > 0).astype(int)\n",
    "\n",
    "df = df.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1aa64b-a80a-44b6-bbc6-4c279281a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Feature Engineering for Predicting 1-Day Ahead Returns (NU ADR)\n",
    "# ==============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# --- Load Data ---\n",
    "df = pd.read_csv(\"adr_prices_and_vol.csv\", parse_dates=[\"Date\"])\n",
    "ticker = \"NU\"\n",
    "\n",
    "# --- Basic Features ---\n",
    "df[\"Return_1d\"] = df[f\"{ticker}_Price\"].pct_change()\n",
    "df[\"Vol_5d\"] = df[\"Return_1d\"].rolling(5).std()\n",
    "df[\"MA_10\"] = df[f\"{ticker}_Price\"].rolling(10).mean()\n",
    "df[\"MA_20\"] = df[f\"{ticker}_Price\"].rolling(20).mean()\n",
    "df[\"MA_50\"] = df[f\"{ticker}_Price\"].rolling(50).mean()\n",
    "df[\"MA_ratio\"] = df[\"MA_10\"] / df[\"MA_50\"] - 1\n",
    "\n",
    "# --- Momentum Features ---\n",
    "df[\"Mom_5d\"] = df[\"Return_1d\"].rolling(5).sum()\n",
    "df[\"Mom_20d\"] = df[\"Return_1d\"].rolling(20).sum()\n",
    "\n",
    "# --- Higher Moments ---\n",
    "window = 20\n",
    "df[\"Skew_20d\"] = df[\"Return_1d\"].rolling(window).apply(lambda x: skew(x, bias=False), raw=False)\n",
    "df[\"Kurt_20d\"] = df[\"Return_1d\"].rolling(window).apply(lambda x: kurtosis(x, fisher=True, bias=False), raw=False)\n",
    "\n",
    "# --- Volatility Ratios ---\n",
    "df[\"Vol_20d\"] = df[\"Return_1d\"].rolling(20).std()\n",
    "df[\"Vol_ratio\"] = (df[\"Vol_5d\"] / df[\"Vol_20d\"].replace(0, np.nan)) - 1\n",
    "\n",
    "# --- Trend / Mean-Reversion ---\n",
    "df[\"Zscore_20d\"] = (df[f\"{ticker}_Price\"] - df[\"MA_20\"]) / df[\"Vol_20d\"].replace(0, np.nan)\n",
    "df[\"Trend_10_50\"] = (df[\"MA_10\"] > df[\"MA_50\"]).astype(int)\n",
    "\n",
    "# --- Liquidity (if available) ---\n",
    "if f\"{ticker}_Volume\" in df.columns:\n",
    "    df[\"Vol_Change_5d\"] = df[f\"{ticker}_Volume\"].pct_change(5)\n",
    "    df[\"Vol_SMA_ratio\"] = (\n",
    "        df[f\"{ticker}_Volume\"].rolling(5).mean() / df[f\"{ticker}_Volume\"].rolling(20).mean() - 1\n",
    "    )\n",
    "\n",
    "# --- RSI ---\n",
    "delta = df[f\"{ticker}_Price\"].diff()\n",
    "gain = delta.clip(lower=0)\n",
    "loss = -delta.clip(upper=0)\n",
    "rs = gain.rolling(14).mean() / loss.rolling(14).mean().replace(0, np.nan)\n",
    "df[\"RSI_14\"] = 100 - (100 / (1 + rs.replace([np.inf, -np.inf, 0], np.nan)))\n",
    "\n",
    "# --- Target ---\n",
    "df[\"Target\"] = (df[\"Return_1d\"].shift(-1) > 0).astype(int)\n",
    "\n",
    "# --- Cleanup ---\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec4297-d96b-4d57-9b3b-1cc4765303e3",
   "metadata": {},
   "source": [
    "### 2. Feature Standardization (Z-Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209dad7-b695-430d-9780-7e75a65cd20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Feature Scaling (Standardization)\n",
    "# ==============================================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Select Features ---\n",
    "feature_cols = [\n",
    "    \"Return_1d\", \"Vol_5d\", \"MA_ratio\", \"Mom_5d\", \"Mom_20d\",\n",
    "    \"Skew_20d\", \"Kurt_20d\", \"Vol_ratio\", \"RSI_14\", \"Trend_10_50\"\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "\n",
    "# --- Standardize Features ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- Convert Back to DataFrame ---\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=feature_cols, index=df.index)\n",
    "\n",
    "# --- Quick Sanity Check ---\n",
    "X_scaled.describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3902f66-661d-47d3-9cb8-8adbf00e75be",
   "metadata": {},
   "source": [
    "### 3. Pairwise Feature Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5b407-e7af-4d32-89ee-db3b3e017cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Pairplot — Full Feature Relationships (NU ADR)\n",
    "# ==============================================================\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Select all engineered features ---\n",
    "all_features = [\n",
    "    \"Return_1d\", \"Vol_5d\", \"MA_ratio\", \"Mom_5d\", \"Mom_20d\",\n",
    "    \"Skew_20d\", \"Kurt_20d\", \"Vol_ratio\", \"RSI_14\", \"Trend_10_50\"\n",
    "]\n",
    "\n",
    "# --- Subsample if needed (to make plot manageable) ---\n",
    "# Optional: if you have thousands of rows, uncomment the line below\n",
    "# df_sample = df.sample(300, random_state=42)\n",
    "# else just use df directly\n",
    "df_sample = df.copy()\n",
    "\n",
    "# --- Create pairplot ---\n",
    "sns.pairplot(\n",
    "    df_sample,\n",
    "    vars=all_features,\n",
    "    hue=\"Target\",\n",
    "    diag_kind=\"kde\",\n",
    "    corner=True,  # show only lower triangle to avoid clutter\n",
    "    plot_kws={'alpha': 0.5, 's': 15, 'edgecolor': 'none'}\n",
    ")\n",
    "\n",
    "plt.suptitle(\"NU ADR — Full Feature Relationships (10 Variables)\", y=1.02, fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3d718-c3c7-43c5-b9d0-9483bc2db142",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "corr = df[all_features].corr()\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", annot=True, fmt=\".2f\", center=0)\n",
    "plt.title(\"NU ADR — Feature Correlation Matrix\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eb442c-3eec-46d9-acd0-aeb182c05c7a",
   "metadata": {},
   "source": [
    "### 4. Logistic Regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286bb6d0-bbf7-4bc1-8276-dd478bb86bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 4. Logistic Regression Pipeline — Predicting Next-Day Direction\n",
    "# ==============================================================\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# --- Features & Target ---\n",
    "features = [\n",
    "    \"Return_1d\", \"Vol_5d\", \"MA_ratio\", \"Mom_5d\", \"Mom_20d\",\n",
    "    \"Skew_20d\", \"Kurt_20d\", \"Vol_ratio\", \"RSI_14\", \"Trend_10_50\"\n",
    "]\n",
    "X = df[features]\n",
    "y = df[\"Target\"].values\n",
    "\n",
    "# --- Chronological Split (80 / 20) ---\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# --- Pipeline: Standardization + Logistic Regression ---\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate ---\n",
    "train_acc = pipe.score(X_train, y_train)\n",
    "test_acc  = pipe.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.3f}\")\n",
    "print(f\"Test  Accuracy: {test_acc:.3f}\")\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pipe.predict(X_test))).plot(cmap=\"Blues\")\n",
    "plt.title(\"NU ADR — Logistic Regression Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47ad9e-26db-4365-abda-9cab73c7e649",
   "metadata": {},
   "source": [
    "### 5. Logistic Decision Boundary (Optional Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24077f4f-6b3f-44ec-852c-052e8c8eb6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 5. Logistic Regression Decision Boundary (NU ADR)\n",
    "# ==============================================================\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# --- Select two features for visualization ---\n",
    "feat1, feat2 = \"Return_1d\", \"MA_ratio\"\n",
    "X2 = df[[feat1, feat2]].values\n",
    "y2 = df[\"Target\"].values\n",
    "\n",
    "# --- Train pipeline (scaled logistic regression) ---\n",
    "pipe2 = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "pipe2.fit(X2, y2)\n",
    "\n",
    "# --- Mesh grid over feature space ---\n",
    "x_min, x_max = X2[:, 0].min() - 0.02, X2[:, 0].max() + 0.02\n",
    "y_min, y_max = X2[:, 1].min() - 0.02, X2[:, 1].max() + 0.02\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    "Z = pipe2.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "# --- Plot decision boundary and observations ---\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.contourf(xx, yy, Z, alpha=0.25, cmap=ListedColormap([\"#FF9999\", \"#99CC99\"]))\n",
    "plt.scatter(X2[:, 0], X2[:, 1], c=y2, edgecolors='k', cmap=\"bwr\", alpha=0.7)\n",
    "plt.xlabel(feat1)\n",
    "plt.ylabel(feat2)\n",
    "plt.title(\"NU ADR — Logistic Regression Decision Regions\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b805eff-1b15-46a5-aa00-3cdd5613dc86",
   "metadata": {},
   "source": [
    "####  Challenge 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4cd971-a794-4562-a102-5bd96501a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Chapter 2 – Challenge 1: k-Fold Cross-Validation (NU ADR)\n",
    "# ==============================================================\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# --- Feature Matrix & Target ---\n",
    "X = df[[\n",
    "    \"Return_1d\", \"Vol_5d\", \"MA_ratio\", \"Mom_5d\", \"Mom_20d\",\n",
    "    \"Skew_20d\", \"Kurt_20d\", \"Vol_ratio\", \"RSI_14\", \"Trend_10_50\"\n",
    "]].values\n",
    "y = df[\"Target\"].values\n",
    "\n",
    "# --- Model Pipeline ---\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    ")\n",
    "\n",
    "# --- 5-Fold Cross Validation ---\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipe, X, y, cv=kf, scoring=\"accuracy\")\n",
    "\n",
    "print(\"=== Logistic Regression 5-Fold CV Results ===\")\n",
    "print(f\"Fold Accuracies : {cv_scores.round(3)}\")\n",
    "print(f\"Mean Accuracy   : {cv_scores.mean():.3f}\")\n",
    "print(f\"Std Deviation   : {cv_scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201efbb8-c033-46e4-af5a-f2e37c2e9e56",
   "metadata": {},
   "source": [
    "####  Challenge 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d3a066-5b0b-4ad1-8b81-91d57735c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Chapter 2 – Challenge 2: 2D Decision Boundary Visualization (NU ADR)\n",
    "# ==============================================================\n",
    "\n",
    "# --- Choose two features for visualization ---\n",
    "feat1, feat2 = \"Return_1d\", \"MA_ratio\"\n",
    "X2 = df[[feat1, feat2]].values\n",
    "y2 = df[\"Target\"].values\n",
    "\n",
    "# --- Standardization + Logistic Regression pipeline ---\n",
    "pipe2 = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    ")\n",
    "pipe2.fit(X2, y2)\n",
    "\n",
    "# --- Create a meshgrid for decision boundary ---\n",
    "x_min, x_max = X2[:, 0].min() - 0.02, X2[:, 0].max() + 0.02\n",
    "y_min, y_max = X2[:, 1].min() - 0.02, X2[:, 1].max() + 0.02\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(x_min, x_max, 200),\n",
    "    np.linspace(y_min, y_max, 200)\n",
    ")\n",
    "\n",
    "# --- Predict over the meshgrid ---\n",
    "Z = pipe2.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "# --- Plot Decision Regions ---\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.contourf(xx, yy, Z, alpha=0.25, cmap=ListedColormap([\"#FF9999\", \"#99CC99\"]))\n",
    "plt.scatter(X2[:, 0], X2[:, 1], c=y2, edgecolors=\"k\", cmap=\"bwr\", s=30, alpha=0.6)\n",
    "plt.xlabel(feat1)\n",
    "plt.ylabel(feat2)\n",
    "plt.title(f\"NU ADR – Logistic Regression Decision Boundary ({feat1} vs {feat2})\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d052e34-0dca-4de1-82b7-ae37a9f41ced",
   "metadata": {},
   "source": [
    "####  Challenge 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772cdce-9670-4509-89f6-42b07591ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Chapter 2 – Challenge 3: Minimal Data Pipeline API (NU ADR)\n",
    "# ==============================================================\n",
    "\n",
    "# --- Custom StandardScaler Class ---\n",
    "class MyScaler:\n",
    "    \"\"\"Minimal reimplementation of scikit-learn's StandardScaler.\"\"\"\n",
    "    def fit(self, X):\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        self.std_ = np.std(X, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X - self.mean_) / (self.std_ + 1e-8)  # avoid division by zero\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "# --- Load & Prepare NU ADR Features ---\n",
    "df = pd.read_csv(\"adr_prices_and_vol.csv\", parse_dates=[\"Date\"])\n",
    "ticker = \"NU\"\n",
    "\n",
    "df[\"Return_1d\"] = df[f\"{ticker}_Price\"].pct_change()\n",
    "df[\"Vol_5d\"] = df[\"Return_1d\"].rolling(5).std()\n",
    "df[\"MA_10\"] = df[f\"{ticker}_Price\"].rolling(10).mean()\n",
    "df[\"MA_50\"] = df[f\"{ticker}_Price\"].rolling(50).mean()\n",
    "df[\"MA_ratio\"] = df[\"MA_10\"] / df[\"MA_50\"] - 1\n",
    "df[\"Target\"] = (df[\"Return_1d\"].shift(-1) > 0).astype(int)\n",
    "df = df.dropna().copy()\n",
    "\n",
    "# --- Select Features & Split ---\n",
    "X = df[[\"Return_1d\", \"Vol_5d\", \"MA_ratio\"]].values\n",
    "y = df[\"Target\"].values\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# --- Apply Custom Scaler ---\n",
    "scaler = MyScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Train Logistic Regression ---\n",
    "clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {acc:.3f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7524ee8b-c333-4df4-b610-bb227a1ffc3c",
   "metadata": {},
   "source": [
    "---\n",
    "## Chapter 3 – Model Evaluation and Cross-Validation\n",
    "---\n",
    "\n",
    "Ex 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89999819-75a8-4102-9a0e-9cf7b315fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "X = pd.DataFrame({\n",
    "    \"lag1\": returns.shift(1),\n",
    "    \"vol5\": returns.rolling(5).std()\n",
    "}).dropna()\n",
    "\n",
    "y = (returns[-len(X):] > 0).astype(int).values  # binary target\n",
    "\n",
    "# --- Chronological Split (60/20/20) ---\n",
    "n = len(X)\n",
    "n_train, n_val = int(0.6 * n), int(0.2 * n)\n",
    "X_train, X_val, X_test = X[:n_train], X[n_train:n_train+n_val], X[n_train+n_val:]\n",
    "y_train, y_val, y_test = y[:n_train], y[n_train:n_train+n_val], y[n_train+n_val:]\n",
    "\n",
    "# --- Pipelines ---\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s, X_val_s, X_test_s = scaler.transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n",
    "\n",
    "clf_lr  = LogisticRegression().fit(X_train_s, y_train)\n",
    "clf_svc = SVC(kernel=\"linear\").fit(X_train_s, y_train)\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred_lr  = clf_lr.predict(X_test_s)\n",
    "y_pred_svc = clf_svc.predict(X_test_s)\n",
    "\n",
    "acc_lr  = accuracy_score(y_test, y_pred_lr)\n",
    "acc_svc = accuracy_score(y_test, y_pred_svc)\n",
    "\n",
    "print(f\"Test Accuracy → LogisticRegression: {acc_lr:.3f},  Linear SVC: {acc_svc:.3f}\")\n",
    "print(\"Confusion Matrix (LR):\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"Confusion Matrix (SVC):\\n\", confusion_matrix(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abac40-db9a-4928-bbf1-181cfeae6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, Xs, y, title):\n",
    "\n",
    "    x_min, x_max = Xs[:, 0].min() - 1, Xs[:, 0].max() + 1\n",
    "    y_min, y_max = Xs[:, 1].min() - 1, Xs[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, cmap=ListedColormap([\"#FFBBBB\", \"#BBFFBB\"]), alpha=0.25)\n",
    "    plt.scatter(Xs[:, 0], Xs[:, 1], c=y, cmap=ListedColormap([\"#FF0000\", \"#00AA00\"]),\n",
    "                edgecolor=\"k\", s=30, alpha=0.8)\n",
    "    plt.xlabel(\"lag1 (standardized)\")\n",
    "    plt.ylabel(\"vol5 (standardized)\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary(clf_lr,  X_test_s, y_test, \"Logistic Regression Boundary\")\n",
    "plot_decision_boundary(clf_svc, X_test_s, y_test, \"Linear SVC Boundary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1509c5f3-1831-4298-a28a-cf16de1f9c4d",
   "metadata": {},
   "source": [
    "Ex 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca28633-1e3f-4870-8300-2548fc70a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# --- Feature setup ---\n",
    "X = pd.DataFrame({\n",
    "    \"lag1\": returns.shift(1),\n",
    "    \"vol5\": returns.rolling(5).std()\n",
    "}).dropna()\n",
    "y = returns[-len(X):].values  # use raw returns, not signs\n",
    "\n",
    "# --- Chronological split (60/20/20) ---\n",
    "n = len(X)\n",
    "n_train, n_val = int(0.6*n), int(0.2*n)\n",
    "X_train, X_val, X_test = X[:n_train], X[n_train:n_train+n_val], X[n_train+n_val:]\n",
    "y_train, y_val, y_test = y[:n_train], y[n_train:n_train+n_val], y[n_train+n_val:]\n",
    "\n",
    "# --- Standardize ---\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "# --- Linear Regression baseline ---\n",
    "lin_reg = LinearRegression().fit(X_train_s, y_train)\n",
    "y_pred_lin = lin_reg.predict(X_test_s)\n",
    "r2_lin = r2_score(y_test, y_pred_lin)\n",
    "print(f\"Linear Regression R²: {r2_lin:.4f}\")\n",
    "\n",
    "# --- Polynomial Features (degree=2) ---\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_s)\n",
    "X_test_poly  = poly.transform(X_test_s)\n",
    "\n",
    "poly_reg = LinearRegression().fit(X_train_poly, y_train)\n",
    "y_pred_poly = poly_reg.predict(X_test_poly)\n",
    "r2_poly = r2_score(y_test, y_pred_poly)\n",
    "print(f\"Polynomial (deg=2) Regression R²: {r2_poly:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf95dbcd-9ae6-405d-9278-ffde55929b95",
   "metadata": {},
   "source": [
    "#### Residual Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f3fb9-99eb-4e2a-91c8-c7830d5121bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Residuals ---\n",
    "res_lin  = y_test - y_pred_lin\n",
    "res_poly = y_test - y_pred_poly\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "ax[0].scatter(y_pred_lin, res_lin, color=\"gray\", alpha=0.7)\n",
    "ax[0].axhline(0, color=\"red\", linestyle=\"--\")\n",
    "ax[0].set_title(\"Residuals: Linear Regression\")\n",
    "ax[0].set_xlabel(\"Predicted returns\")\n",
    "ax[0].set_ylabel(\"Residuals\")\n",
    "\n",
    "ax[1].scatter(y_pred_poly, res_poly, color=\"navy\", alpha=0.7)\n",
    "ax[1].axhline(0, color=\"red\", linestyle=\"--\")\n",
    "ax[1].set_title(\"Residuals: Polynomial Regression (deg=2)\")\n",
    "ax[1].set_xlabel(\"Predicted returns\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11b6831-5a97-42bc-98fe-bcabc630e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear Coefficients:\", lin_reg.coef_)\n",
    "print(\"Polynomial Coefficients (first 5):\", poly_reg.coef_[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a658cfc-5fff-4901-b52b-1d155b768cd9",
   "metadata": {},
   "source": [
    "| Finding          | Implication                                  |\n",
    "| ---------------- | -------------------------------------------- |\n",
    "| (R^2 < 0)        | No linear or quadratic predictive structure. |\n",
    "| Coefficients ≈ 0 | Predictors have no meaningful slope.         |\n",
    "| Residuals random | The model is unbiased but uninformative.     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa298ff-1054-4a28-9ab7-3a3cd5ea30b4",
   "metadata": {},
   "source": [
    "Ex 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ec034-f91b-4982-ad20-0eced791cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = pd.DataFrame({\n",
    "    \"lag1\": returns.shift(1),\n",
    "    \"vol5\": returns.rolling(5).std()\n",
    "}).dropna()\n",
    "y = (returns[-len(X):] > 0).astype(int).values\n",
    "\n",
    "# --- Chronological split (60/20/20) ---\n",
    "n = len(X)\n",
    "n_train, n_val = int(0.6*n), int(0.2*n)\n",
    "X_train, X_val, X_test = X[:n_train], X[n_train:n_train+n_val], X[n_train+n_val:]\n",
    "y_train, y_val, y_test = y[:n_train], y[n_train:n_train+n_val], y[n_train+n_val:]\n",
    "\n",
    "# --- Fit shallow and deep trees ---\n",
    "tree_shallow = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree_deep    = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "\n",
    "tree_shallow.fit(X_train, y_train)\n",
    "tree_deep.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate ---\n",
    "for name, model in [(\"Shallow\", tree_shallow), (\"Deep\", tree_deep)]:\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    depth = model.get_depth()\n",
    "    leaves = model.get_n_leaves()\n",
    "    print(f\"{name} Tree → depth={depth}, leaves={leaves}, test acc={acc:.3f}\")\n",
    "    print(\"Confusion:\\n\", confusion_matrix(y_test, y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e750cb-cb47-4608-a37d-dc78076e7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Decision Tree Boundary Plotter (final clean version) ---\n",
    "def plot_tree_boundary(model, X, y, title):\n",
    "    h = 0.02\n",
    "    x_min, x_max = X.iloc[:,0].min() - 0.5, X.iloc[:,0].max() + 0.5\n",
    "    y_min, y_max = X.iloc[:,1].min() - 0.5, X.iloc[:,1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # wrap prediction grid as DataFrame with same feature names\n",
    "    grid_df = pd.DataFrame(np.c_[xx.ravel(), yy.ravel()],\n",
    "                           columns=X.columns)\n",
    "    \n",
    "    Z = model.predict(grid_df).reshape(xx.shape)\n",
    "    \n",
    "    # --- Plot ---\n",
    "    plt.contourf(xx, yy, Z, cmap=ListedColormap([\"#FFBBBB\", \"#BBFFBB\"]), alpha=0.25)\n",
    "    plt.scatter(X.iloc[:,0], X.iloc[:,1], c=y,\n",
    "                cmap=ListedColormap([\"#FF0000\", \"#00AA00\"]),\n",
    "                edgecolor=\"k\", s=30)\n",
    "    plt.xlabel(\"lag1\"); plt.ylabel(\"vol5\")\n",
    "    plt.title(title)\n",
    "\n",
    "# --- 🧩 CALL THE FUNCTION FOR BOTH TREES ---\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_tree_boundary(tree_shallow, X_test, y_test, \"Shallow Tree (max_depth=3)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_tree_boundary(tree_deep, X_test, y_test, \"Deep Tree (max_depth=10)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681e124-18da-4dd8-9866-305a3e7b5c5a",
   "metadata": {},
   "source": [
    "| Finding                                     | Implication                          |\n",
    "| ------------------------------------------- | ------------------------------------ |\n",
    "| Depth ↑ → complexity ↑ but no accuracy gain | Evidence of overfitting noise        |\n",
    "| Both accuracies ≈ 0.5                       | No predictive structure              |\n",
    "| Visual fragmentation in deep tree           | Classic overfit in low-signal domain |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b7838-4a5b-44a1-ae6f-9e7a62fc49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f20d90-31b7-4f56-8376-32356b0fcf69",
   "metadata": {},
   "source": [
    "- Financial reality – Lagged return and short-term volatility carry almost no predictive power for the next return sign.\n",
    "\n",
    "- The model learns trivial partitions near zero and outputs ≈ 50 % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012d62b-2b79-47cd-8382-46862e8a8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = X_test.copy()\n",
    "X_plot['lag1'] *= 100      # convert to %\n",
    "X_plot['vol5'] *= 100\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plot_tree_boundary(tree_shallow, X_plot, y_test, \"Shallow Tree (max_depth=3, % scale)\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plot_tree_boundary(tree_deep, X_plot, y_test, \"Deep Tree (max_depth=10, % scale)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6db9b-0c96-4e7d-9f90-038010eb7f8e",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "\n",
    "- Linear methods (Logistic, SVC) and polynomial expansions show **no predictive structure** in single-asset daily returns — consistent with market efficiency.\n",
    "\n",
    "- Decision trees illustrate variance explosion with depth on noisy data.\n",
    "\n",
    "- Residuals and decision boundaries confirm the same principle: randomness dominates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee0972-4915-4b5e-b89f-f5ef69917382",
   "metadata": {},
   "source": [
    "Ex 1 chapter 3 (Pdf slides) Regression Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d27c97-08de-4364-bdea-032106d8ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# --- Fixed random seed for reproducibility ---\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Generate noisy linear data ---\n",
    "n = 200\n",
    "X = np.linspace(-3, 3, n).reshape(-1, 1)\n",
    "y_true = 0.8 * X.squeeze() + 0.5          # underlying signal\n",
    "noise = np.random.normal(0, 0.4, size=n)  # Gaussian noise\n",
    "y = y_true + noise                        # observed target\n",
    "\n",
    "# --- Train/Validation/Test split (60/20/20) ---\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "# --- Fit Linear Regression ---\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# --- Predictions ---\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_val   = model.predict(X_val)\n",
    "y_pred_test  = model.predict(X_test)\n",
    "\n",
    "# --- Metrics ---\n",
    "def report_metrics(y_true, y_pred, label):\n",
    "    print(f\"{label:>5} | R²={r2_score(y_true, y_pred):.3f}  \"\n",
    "          f\"MSE={mean_squared_error(y_true, y_pred):.3f}  \"\n",
    "          f\"MAE={mean_absolute_error(y_true, y_pred):.3f}\")\n",
    "\n",
    "report_metrics(y_train, y_pred_train, \"Train\")\n",
    "report_metrics(y_val,   y_pred_val,   \"Val\")\n",
    "report_metrics(y_test,  y_pred_test,  \"Test\")\n",
    "\n",
    "# --- Visualization ---\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.scatter(X_train, y_train, color=\"gray\", alpha=0.5, label=\"Train data\")\n",
    "plt.scatter(X_test,  y_test,  color=\"blue\", alpha=0.5, label=\"Test data\")\n",
    "plt.plot(X, y_true, \"k--\", label=\"True relationship\")\n",
    "plt.plot(X, model.predict(X), \"r\", label=\"Fitted line\")\n",
    "plt.legend(); plt.title(\"Noisy Linear Regression Toy\"); plt.show()\n",
    "\n",
    "# --- Residual plot ---\n",
    "residuals = y_test - y_pred_test\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.scatter(y_pred_test, residuals, color=\"purple\", alpha=0.7)\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted y\"); plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Predicted (Test set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becce35b-58b7-474a-9b74-6eba771fbdc8",
   "metadata": {},
   "source": [
    "| Concept                     | Insight                                                                                                              |\n",
    "| --------------------------- | -------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Bias–Variance Trade-off** | Train fit is strong; test degradation comes purely from variance due to noise, not model bias.                       |\n",
    "| **Residual Diagnostics**    | Random scatter → residuals ≈ i.i.d. N(0, σ²). Model specification is correct.                                        |\n",
    "| **Predictive Power**        | (R^2_{test}) ≈ 0.18 means the linear model explains 18 % of total variance — reasonable given synthetic noise level. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc857c-f60a-4378-ab65-27029675c39e",
   "metadata": {},
   "source": [
    "#### Challenge 1: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643879bb-9855-4fce-b019-e31aa0afd7f2",
   "metadata": {},
   "source": [
    "#### Step 1 — Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac40f2-8207-46e5-a8d0-b9ef09a6a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d568b997-3fad-4666-8f24-c3c6b9238d85",
   "metadata": {},
   "source": [
    "#### Step 2 — Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94008d26-6f3d-4108-90c1-e29df178b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature engineering (same as before) ---\n",
    "X = pd.DataFrame({\n",
    "    \"lag1\": returns.shift(1),\n",
    "    \"vol5\": returns.rolling(5).std()\n",
    "}).dropna()\n",
    "y = (returns[-len(X):] > 0).astype(int).values\n",
    "\n",
    "# --- Chronological split (60/20/20) ---\n",
    "n = len(X)\n",
    "n_train, n_val = int(0.6*n), int(0.2*n)\n",
    "X_train, X_val, X_test = X[:n_train], X[n_train:n_train+n_val], X[n_train+n_val:]\n",
    "y_train, y_val, y_test = y[:n_train], y[n_train:n_train+n_val], y[n_train+n_val:]\n",
    "\n",
    "# --- Define CV strategy ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2afdc7-dc06-403a-877c-6f036a37c8d6",
   "metadata": {},
   "source": [
    "#### Step 3 — Tune RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a14494-e2c8-4e37-a170-ad7c6c9094f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pipeline: standardize + SVM ---\n",
    "pipe_svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf'))\n",
    "])\n",
    "\n",
    "# --- Parameter grid ---\n",
    "param_grid_svm = {\n",
    "    'svm__C': [0.1, 1, 10, 100],\n",
    "    'svm__gamma': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# --- Grid Search with Stratified CV ---\n",
    "grid_svm = GridSearchCV(pipe_svm, param_grid_svm, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "# --- Results ---\n",
    "print(\"Best RBF SVM Parameters:\", grid_svm.best_params_)\n",
    "print(f\"Best CV Accuracy: {grid_svm.best_score_:.3f}\")\n",
    "\n",
    "# --- Evaluate on test set ---\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_svm):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e4ef3-36f6-4202-9115-300c0b9468c9",
   "metadata": {},
   "source": [
    "#### Step 4 — Tune Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870987a1-0b8c-4b21-a881-11fdd1700ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tree model ---\n",
    "param_grid_tree = {'max_depth': [1, 2, 3, 5, 8, 12, 15, None]}\n",
    "\n",
    "grid_tree = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid_tree,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "# --- Results ---\n",
    "print(f\"Best Tree Depth: {grid_tree.best_params_['max_depth']}\")\n",
    "print(f\"Best CV Accuracy: {grid_tree.best_score_:.3f}\")\n",
    "\n",
    "# --- Evaluate on test set ---\n",
    "y_pred_tree = grid_tree.predict(X_test)\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_tree):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6743912-5271-4869-a9f1-f9e5de1ad92c",
   "metadata": {},
   "source": [
    "#### Step 5 — Plot Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5197ce-3627-4edf-995b-adc79622ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot heatmap for SVM grid search results ---\n",
    "svm_results = pd.DataFrame(grid_svm.cv_results_)\n",
    "scores = svm_results.pivot(index='param_svm__gamma', columns='param_svm__C', values='mean_test_score')\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(scores, interpolation='nearest', cmap='viridis')\n",
    "plt.title(\"RBF SVM Grid Search (CV Accuracy)\")\n",
    "plt.xlabel(\"C\"); plt.ylabel(\"gamma\")\n",
    "plt.colorbar(label=\"CV Accuracy\")\n",
    "plt.xticks(range(len(param_grid_svm['svm__C'])), param_grid_svm['svm__C'])\n",
    "plt.yticks(range(len(param_grid_svm['svm__gamma'])), param_grid_svm['svm__gamma'])\n",
    "plt.show()\n",
    "\n",
    "# --- Plot Tree Depth vs Accuracy ---\n",
    "tree_results = pd.DataFrame(grid_tree.cv_results_)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(param_grid_tree['max_depth'], tree_results['mean_test_score'], marker='o')\n",
    "plt.title(\"Decision Tree: Validation Accuracy vs max_depth\")\n",
    "plt.xlabel(\"Max Depth\"); plt.ylabel(\"CV Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfc19a-c9cb-4d80-a40d-66c549a1e116",
   "metadata": {},
   "source": [
    "#### Challenge 2: Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc692263-681f-4383-866e-2b09b0ab774c",
   "metadata": {},
   "source": [
    "#### Step 1 — Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad23b96-919a-47a4-ae30-01ad1e663036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84254497-017e-4880-9529-091fc849fdc1",
   "metadata": {},
   "source": [
    "#### Step 2 — Generate Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf8f98b-8997-4411-8961-913c413f64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strongly imbalanced binary dataset (90% of class 0)\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=2, n_informative=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.9, 0.1],\n",
    "    flip_y=0.02, random_state=42\n",
    ")\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeebfe2-6f8e-482d-aba2-f5f2a690c206",
   "metadata": {},
   "source": [
    "#### Step 3 — Fit a Baseline Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354a856-4737-46b1-89f6-f44f30b25b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de4cca-f2cd-4b1f-9d12-5ca6c1110343",
   "metadata": {},
   "source": [
    "#### Step 4 — Evaluate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b061bc45-bb7e-442a-bba3-195aeea65483",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(f\"Accuracy : {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall   : {rec:.3f}\")\n",
    "print(f\"F1-score : {f1:.3f}\")\n",
    "print(f\"ROC AUC  : {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e60ea-d0ae-4320-9323-b5096f09a7d8",
   "metadata": {},
   "source": [
    "#### Step 5 — Plot ROC and PR Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec7e2b-3b8c-4720-a1a1-4f873362b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ROC Curve ---\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0,1], [0,1], 'k--', alpha=0.6)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "\n",
    "# --- Precision-Recall Curve ---\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_prob)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(rec_curve, prec_curve)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision–Recall Curve\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e1621-a22d-4bac-9b03-90fa823cd80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bal = LogisticRegression(class_weight='balanced')\n",
    "clf_bal.fit(X_train, y_train)\n",
    "print(\"Balanced F1:\", f1_score(y_test, clf_bal.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82408535-fa28-4c69-8ba0-c9b9649b6bfd",
   "metadata": {},
   "source": [
    "## Results Recap\n",
    "\n",
    "| Metric        |  Baseline | With `class_weight='balanced'` | Interpretation                                                                     |\n",
    "| :------------ | :-------: | :----------------------------: | :--------------------------------------------------------------------------------- |\n",
    "| **Accuracy**  |   0.973   | 0.956 (≈ expected slight drop) | Accuracy dominated by majority class — not a reliable metric here.                 |\n",
    "| **Precision** | **1.000** |           ↓ slightly           | Model almost never produces false positives, but may miss true ones.               |\n",
    "| **Recall**    | **0.758** |   ↑ slightly after balancing   | Model captures more minority positives with weighting.                             |\n",
    "| **F1-score**  |   0.862   |              0.853             | Balanced model trades a bit of precision for recall — overall robustness improves. |\n",
    "| **ROC AUC**   | **0.995** |             ≈ same             | Strong separation between classes — high rank consistency.                         |\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "### ROC Curve\n",
    "\n",
    "* **AUC = 0.995** shows the classifier ranks positive cases almost perfectly.\n",
    "* Near-square shape (upper-left corner) means the model discriminates cleanly.\n",
    "\n",
    "### Precision–Recall Curve\n",
    "\n",
    "* Extremely high precision at moderate recall indicates **rare-event dominance** — the model confidently identifies most positives with almost no false alarms.\n",
    "* The small dip near recall ≈ 1 reflects the final few borderline cases.\n",
    "\n",
    "### Insight\n",
    "\n",
    "In financial ML, this scenario parallels *rare profitable trades* or *default prediction*:\n",
    "\n",
    "> It’s better to **capture fewer true positives with high precision** than to flood the book with false signals.\n",
    "\n",
    "However, recall becomes crucial if missing positives has a high opportunity cost — hence why **balanced weighting** is introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6b5be-895c-435b-bd2b-9227c2dc936c",
   "metadata": {},
   "source": [
    "#### Challenge 3 – Probability Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197e1f25-f3ca-4730-aa82-6500e7f678b5",
   "metadata": {},
   "source": [
    "#### Step 1 — Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37392997-3b2a-4110-be25-6e7a143797d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import (\n",
    "    brier_score_loss, roc_auc_score, precision_score, recall_score, f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3168418-c5ec-490f-9f1f-981a670e9e87",
   "metadata": {},
   "source": [
    "#### Step 2 — Generate a Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d168aa11-3295-4173-9b72-9f96c8cfb53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Synthetic balanced binary classification ---\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=2, n_informative=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, random_state=42\n",
    ")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c5a0b6-76ad-4e4b-9f85-f879b8a1129d",
   "metadata": {},
   "source": [
    "#### Step 3 — Fit Uncalibrated SVM (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e90a355-630a-45c2-9161-cf699eaf72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SVM with RBF kernel (uncalibrated probabilities) ---\n",
    "svm_uncal = SVC(kernel='rbf', C=1.0, gamma=0.5, probability=False, random_state=42)\n",
    "svm_uncal.fit(X_train, y_train)\n",
    "\n",
    "# --- Get decision function scores ---\n",
    "scores_uncal = svm_uncal.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41c349e-a691-4147-99cb-72c6fab028c4",
   "metadata": {},
   "source": [
    "#### Step 4 — Fit Calibrated SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3bddef-d1ce-4f8d-8c48-4a93d669c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calibrate using sigmoid (Platt scaling) ---\n",
    "svm_cal = CalibratedClassifierCV(svm_uncal, cv=5, method='sigmoid')\n",
    "svm_cal.fit(X_train, y_train)\n",
    "\n",
    "# --- Predicted probabilities ---\n",
    "probs_cal = svm_cal.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fea49-3847-4802-93b6-7a267a498b2a",
   "metadata": {},
   "source": [
    "#### Step 5 — Compute Calibration Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e25d523-65fd-480e-a125-d5e6616366b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert decision_function scores to [0,1] via sigmoid for comparison\n",
    "from scipy.special import expit\n",
    "probs_uncal = expit(scores_uncal)\n",
    "\n",
    "# --- Brier scores (lower = better) ---\n",
    "brier_uncal = brier_score_loss(y_test, probs_uncal)\n",
    "brier_cal = brier_score_loss(y_test, probs_cal)\n",
    "\n",
    "print(f\"Brier (uncalibrated): {brier_uncal:.4f}\")\n",
    "print(f\"Brier (calibrated):   {brier_cal:.4f}\")\n",
    "\n",
    "# --- Other performance metrics ---\n",
    "print(f\"ROC AUC (uncal): {roc_auc_score(y_test, probs_uncal):.3f}\")\n",
    "print(f\"ROC AUC (cal):   {roc_auc_score(y_test, probs_cal):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7e7dd-a0ce-4999-9d9b-27565f150ae6",
   "metadata": {},
   "source": [
    "#### Step 6 — Plot Reliability Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf14195-e853-4afc-a135-71b831fe8ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true_uncal, prob_pred_uncal = calibration_curve(y_test, probs_uncal, n_bins=10)\n",
    "prob_true_cal, prob_pred_cal = calibration_curve(y_test, probs_cal, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(prob_pred_uncal, prob_true_uncal, \"o-\", label=f\"Uncalibrated (Brier={brier_uncal:.3f})\")\n",
    "plt.plot(prob_pred_cal, prob_true_cal, \"o-\", label=f\"Calibrated (Brier={brier_cal:.3f})\")\n",
    "plt.plot([0,1], [0,1], \"k--\", label=\"Perfect calibration\")\n",
    "plt.xlabel(\"Predicted probability\")\n",
    "plt.ylabel(\"Observed frequency\")\n",
    "plt.title(\"Reliability Diagram (SVM)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf42ab4-78be-40c9-ae44-c72dd6aa3cad",
   "metadata": {},
   "source": [
    "#### Extended Challenge 3 – Platt vs Isotonic Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fec294-35c6-4a1f-b3c0-b10f7b19fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score\n",
    "from scipy.special import expit\n",
    "\n",
    "# --- Data generation ---\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=2, n_informative=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, random_state=42\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# --- Uncalibrated SVM ---\n",
    "svm_uncal = SVC(kernel='rbf', C=1.0, gamma=0.5, probability=False, random_state=42)\n",
    "svm_uncal.fit(X_train, y_train)\n",
    "probs_uncal = expit(svm_uncal.decision_function(X_test))  # convert scores to [0,1]\n",
    "\n",
    "# --- Calibrated SVM (sigmoid / Platt) ---\n",
    "svm_sigmoid = CalibratedClassifierCV(svm_uncal, cv=5, method='sigmoid')\n",
    "svm_sigmoid.fit(X_train, y_train)\n",
    "probs_sigmoid = svm_sigmoid.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# --- Calibrated SVM (isotonic regression) ---\n",
    "svm_isotonic = CalibratedClassifierCV(svm_uncal, cv=5, method='isotonic')\n",
    "svm_isotonic.fit(X_train, y_train)\n",
    "probs_isotonic = svm_isotonic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# --- Compute calibration metrics ---\n",
    "def summarize_model(name, probs):\n",
    "    brier = brier_score_loss(y_test, probs)\n",
    "    auc = roc_auc_score(y_test, probs)\n",
    "    return {\"Model\": name, \"Brier\": brier, \"ROC AUC\": auc}\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    summarize_model(\"Uncalibrated\", probs_uncal),\n",
    "    summarize_model(\"Sigmoid\", probs_sigmoid),\n",
    "    summarize_model(\"Isotonic\", probs_isotonic)\n",
    "])\n",
    "print(summary)\n",
    "\n",
    "# --- Reliability curves ---\n",
    "prob_true_uncal, prob_pred_uncal = calibration_curve(y_test, probs_uncal, n_bins=10)\n",
    "prob_true_sigmoid, prob_pred_sigmoid = calibration_curve(y_test, probs_sigmoid, n_bins=10)\n",
    "prob_true_isotonic, prob_pred_isotonic = calibration_curve(y_test, probs_isotonic, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot(prob_pred_uncal, prob_true_uncal, \"o-\", label=f\"Uncalibrated (Brier={summary.iloc[0]['Brier']:.3f})\")\n",
    "plt.plot(prob_pred_sigmoid, prob_true_sigmoid, \"o-\", label=f\"Sigmoid (Brier={summary.iloc[1]['Brier']:.3f})\")\n",
    "plt.plot(prob_pred_isotonic, prob_true_isotonic, \"o-\", label=f\"Isotonic (Brier={summary.iloc[2]['Brier']:.3f})\")\n",
    "plt.plot([0,1], [0,1], \"k--\", label=\"Perfect calibration\")\n",
    "plt.xlabel(\"Predicted probability\")\n",
    "plt.ylabel(\"Observed frequency\")\n",
    "plt.title(\"Reliability Diagram – SVM Calibration Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00d5894-3b47-4b5d-9edf-93087019e24e",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "| Model               |   Brier   | ROC AUC | Interpretation                                                                                   |\n",
    "| :------------------ | :-------: | :-----: | :----------------------------------------------------------------------------------------------- |\n",
    "| **Uncalibrated**    |   0.072   |  0.984  | Excellent ranking power (AUC ≈ 0.98) but *poor calibration* — probabilities overconfident.       |\n",
    "| **Sigmoid (Platt)** | **0.048** |  0.984  | Substantial improvement — smoother mapping, reduced overconfidence.                              |\n",
    "| **Isotonic**        | **0.047** |  0.979  | Slightly lower AUC (tiny drop due to local overfitting) but *best calibration accuracy* overall. |\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "### **ROC AUC (Ranking Performance)**\n",
    "\n",
    "* Essentially unchanged across models → calibration **does not alter ranking**.\n",
    "* Confirms both Platt and Isotonic preserve discrimination capacity (model ordering of events).\n",
    "\n",
    "### **Brier Score (Calibration Accuracy)**\n",
    "\n",
    "* Sharp reduction from 0.072 → 0.048 → 0.047 confirms **probability quality improved ~35%**.\n",
    "* This corresponds to a better match between predicted probabilities and true event frequencies — critical when using model outputs for position sizing, risk capital allocation, or expected return modeling.\n",
    "\n",
    "### **Reliability Curves**\n",
    "\n",
    "* **Uncalibrated (blue):** classic SVM pattern — steep jump near 0.4–0.6, showing overconfident predictions.\n",
    "* **Sigmoid (green):** near-diagonal, nicely smoothed — good default choice for small/medium datasets.\n",
    "* **Isotonic (red):** piecewise and tightly hugging diagonal — slightly more variance (zigzagging), reflecting nonparametric flexibility.\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation for Quantitative Finance Context\n",
    "\n",
    "| Concept                                       | Relevance                                                                                                                                                                       |\n",
    "| :-------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **Calibrated Probability = Trade Confidence** | In a trading signal model, a 0.8 probability after calibration means historically ≈ 80 % of such signals were correct — critical for position sizing or portfolio risk scaling. |\n",
    "| **Overconfident Models = Mispriced Risk**     | Uncalibrated outputs tend to overweight high-confidence signals (e.g., misestimating Sharpe or VaR).                                                                            |\n",
    "| **Platt vs Isotonic**                         | Use *Platt* for limited or noisy samples (smoother, monotonic). Use *Isotonic* for large samples or when the relationship is clearly nonlinear.                                 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
